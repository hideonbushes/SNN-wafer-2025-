# -*- coding: utf-8 -*-
"""Wafer2Spike_Structured_Notebook.ipynb(05.22 최종 제출본)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tQUOupFMom3zgwNWnaj4fh4duvYoOhMj

BatchNorm을 사용하면 안되는 이유

 SNN은 각 타임스텝마다 membrane potential(state)이 누적되면서 스파이크를 만들어 내는데, 여기에 배치 단위 정규화를 넣으면 시퀀스 전체의 전압 흐름이 일관되지 않게 바뀔 수 있습니다.

 일반 신경망은 model.eval() 시 배치 통계를 고정해서 쓰지만, SNN에서는 상태가 계속 바뀌기 때문에 BatchNorm의 추정 통계(running mean/var)가 실제 분포와 잘 안 맞아 학습·추론 간 불일치가 커질 수 있습니다.
"""

# 1. Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive')

# 2. 필요한 라이브러리 임포트
import pandas as pd

# 3. Wafer 데이터셋 로드
# 파일 위치가 "/MyDrive/WM-811k/LSWMD.pkl"일 경우 아래와 같이 수정
df = pd.read_pickle("/content/drive/MyDrive/WM-811k/LSWMD.pkl")

# 4. 데이터 일부 확인
print("Wafer dataset loaded successfully!")
print(df.head())

"""#기존 Wafer2Spike 논문의 모델
Cg 파라미터를 사용함.
"""

import torch.nn as nn
from torch.distributions.bernoulli import Bernoulli

Cg = 0.3  # Coefficient Gain for surrogate gradient

class PseudoGradSpike(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, vth, cw):
        ctx.save_for_backward(input)
        ctx.vth = vth
        ctx.cw = cw
        return input.gt(vth).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        vth = ctx.vth
        cw = ctx.cw
        grad_input = grad_output.clone()
        spike_pseudo_grad = abs(input - vth) < cw
        return Cg * grad_input * spike_pseudo_grad.float(), None, None


class PseudoGradSpikeWithDropout(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, vth, cw, mask):
        ctx.save_for_backward(input)
        ctx.vth = vth
        ctx.cw = cw
        ctx.mask = mask
        return input.gt(vth).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        vth = ctx.vth
        cw = ctx.cw
        mask = ctx.mask
        grad_input = grad_output.clone()
        spike_pseudo_grad = abs(input - vth) < cw
        spike_pseudo_grad[mask==0] = 0
        return Cg * grad_input * spike_pseudo_grad.float(), None, None, None


class CurrentBasedLIF(nn.Module):
    def __init__(self, func_v, pseudo_grad_ops, param):
        super(CurrentBasedLIF, self).__init__()
        self.func_v = func_v
        self.pseudo_grad_ops = pseudo_grad_ops
        self.w_scdecay, self.w_vdecay, self.vth, self.cw = param

    def forward(self, input_data, state):
        pre_spike, pre_current, pre_volt = state
        current = self.w_scdecay * pre_current + self.func_v(input_data)
        volt = self.w_vdecay * pre_volt * (1. - pre_spike) + current
        output = self.pseudo_grad_ops(volt, self.vth, self.cw)
        return output, (output, current, volt)


class CurrentBasedLIFWithDropout(nn.Module):
    def __init__(self, func_v, pseudo_grad_ops, param):
        super(CurrentBasedLIFWithDropout, self).__init__()
        self.func_v = func_v
        self.pseudo_grad_ops = pseudo_grad_ops
        self.w_scdecay, self.w_vdecay, self.vth, self.cw = param

    def forward(self, input_data, state, mask, train):
        pre_spike, pre_current, pre_volt = state
        current = self.w_scdecay * pre_current + self.func_v(input_data)
        if train is True:
            current = current * mask
        volt = self.w_vdecay * pre_volt * (1. - pre_spike) + current
        output = self.pseudo_grad_ops(volt, self.vth, self.cw, mask)
        return output, (output, current, volt)


class Wafer2Spike(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(Wafer2Spike, self).__init__()
        self.device = device
        self.spike_ts = spike_ts
        self.dropout_fc = dropout_fc
        self.scdecay, self.vdecay, self.vth, self.cw = params

        pseudo_grad_ops = PseudoGradSpike.apply
        pseudo_grad_ops_with_dropout = PseudoGradSpikeWithDropout.apply

        self.conv_spk_enc_w_vdecay = nn.Parameter(torch.ones(1, 64, 30, 30, device=self.device) * self.vdecay)
        self.conv_spk_enc_w_scdecay = nn.Parameter(torch.ones(1, 64, 30, 30, device=self.device) * self.scdecay)

        self.Spk_conv1_w_vdecay = nn.Parameter(torch.ones(1, 64, 12, 12, device=self.device) * self.vdecay)
        self.Spk_conv1_w_scdecay = nn.Parameter(torch.ones(1, 64, 12, 12, device=self.device) * self.scdecay)

        self.Spk_conv2_w_vdecay = nn.Parameter(torch.ones(1, 64, 3, 3, device=self.device) * self.vdecay)
        self.Spk_conv2_w_scdecay = nn.Parameter(torch.ones(1, 64, 3, 3, device=self.device) * self.scdecay)

        self.Spk_fc_w_vdecay = nn.Parameter(torch.ones(1, 256*9, device=self.device) * self.vdecay)
        self.Spk_fc_w_scdecay = nn.Parameter(torch.ones(1, 256*9, device=self.device) * self.scdecay)

        self.w_t = nn.Parameter(torch.ones((self.spike_ts), device=self.device) / self.spike_ts)

        self.conv_spk_enc = CurrentBasedLIF(nn.Conv2d(1, 64, (7, 7), stride=1, bias=True), pseudo_grad_ops,
        [self.conv_spk_enc_w_scdecay, self.conv_spk_enc_w_vdecay, self.vth, self.cw])

        self.Spk_conv1 = CurrentBasedLIF(nn.Conv2d(64, 64, (7, 7), stride=2, bias=True), pseudo_grad_ops,
        [self.Spk_conv1_w_scdecay, self.Spk_conv1_w_vdecay, self.vth, self.cw])

        self.Spk_conv2 = CurrentBasedLIF(nn.Conv2d(64, 64, (7, 7), stride=2, bias=True), pseudo_grad_ops,
        [self.Spk_conv2_w_scdecay, self.Spk_conv2_w_vdecay, self.vth, self.cw])

        self.Spk_fc = CurrentBasedLIFWithDropout(nn.Linear(64*9, 256*9, bias=True), pseudo_grad_ops_with_dropout,
        [self.Spk_fc_w_scdecay, self.Spk_fc_w_vdecay, self.vth, self.cw])

        self.nonSpk_fc = nn.Linear(256*9, numClasses)

    def forward(self, input_data, states):
        batch_size = input_data.shape[0]
        output_spikes = []

        conv_spk_enc_state, Spk_conv1_state, Spk_conv2_state, Spk_fc_state = states[0], states[1], states[2], states[3]

        mask_fc = Bernoulli(
            torch.full_like(torch.zeros(batch_size, 256*9, device=self.device), 1 - self.dropout_fc)
        ).sample() / (1 - self.dropout_fc)

        for step in range(self.spike_ts):
            input_spike = input_data
            conv_spk_enc_spike, conv_spk_enc_state = self.conv_spk_enc(input_spike, conv_spk_enc_state)
            Spk_conv1_spike, Spk_conv1_state = self.Spk_conv1(conv_spk_enc_spike, Spk_conv1_state)
            Spk_conv2_spike, Spk_conv2_state = self.Spk_conv2(Spk_conv1_spike, Spk_conv2_state)

            flattened_spike = Spk_conv2_spike.view(batch_size, -1)
            Spk_fc_spike, Spk_fc_state = self.Spk_fc(flattened_spike, Spk_fc_state, mask_fc, self.training)
            nonSpk_fc_output = self.nonSpk_fc(Spk_fc_spike)
            output_spikes += [nonSpk_fc_output * self.w_t[step]]

        return torch.stack(output_spikes).sum(dim=0)


class CurrentBasedSNN(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(CurrentBasedSNN, self).__init__()
        self.device = device
        self.wafer2spike = Wafer2Spike(numClasses, dropout_fc, spike_ts, device, params)

    def forward(self, input_data):
        batch_size = input_data.shape[0]

        conv_spk_enc_state = tuple(torch.zeros(batch_size, 64, 30, 30, device=self.device) for _ in range(3))
        Spk_conv1_state = tuple(torch.zeros(batch_size, 64, 12, 12, device=self.device) for _ in range(3))
        Spk_conv2_state = tuple(torch.zeros(batch_size, 64, 3, 3, device=self.device) for _ in range(3))
        Spk_fc_state = tuple(torch.zeros(batch_size, 256*9, device=self.device) for _ in range(3))

        states = (conv_spk_enc_state, Spk_conv1_state, Spk_conv2_state, Spk_fc_state)
        return self.wafer2spike(input_data, states)

"""Wafer 데이터 로드 → 증강 → NumPy/OpenCV 전처리 → Tensor 변환 → DataLoader


"""

import os, random
import numpy as np
import pandas as pd
import cv2
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split

# 0) 원하는 Split 비율 설정 (합 = 1.0)
TRAIN_RATIO = 0.6   # 논문대로 6:1:3
VAL_RATIO   = 0.1
TEST_RATIO  = 0.3

# 1) 시드 고정
seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)

# 2) DataFrame 로드
df = pd.read_pickle("/content/drive/MyDrive/WM-811k/LSWMD.pkl")

# 3) try/except 로 레이블 안전 추출
trte = []
for j in df["trianTestLabel"]:
    try:    trte.append(j[0][0])
    except: trte.append(np.nan)
df["trianTestLabel"] = trte

ft = []
for j in df["failureType"]:
    try:    ft.append(j[0][0])
    except: ft.append(np.nan)
df["failureType"] = ft

# 4) 문자열 → 숫자 매핑
map_type = {
    'Center':0,'Donut':1,'Edge-Loc':2,'Edge-Ring':3,
    'Loc':4,'Random':5,'Scratch':6,'Near-full':7,'none':8
}
map_tt = {'Training':0,'Test':1}
df["failureNum"]   = df["failureType"].map(map_type)
df["trainTestNum"] = df["trianTestLabel"].map(map_tt)

# 5) 유효 레이블만 필터링
df = df[df["failureNum"].notna() & df["trainTestNum"].notna()].reset_index(drop=True)
df["failureNum"]   = df["failureNum"].astype(int)
df["trainTestNum"] = df["trainTestNum"].astype(int)

# 6) Training 샘플만 추출
df_train = df[df["trainTestNum"] == 0].reset_index(drop=True)

# 7) Stratified Split: train : temp = TRAIN_RATIO : (1 - TRAIN_RATIO)
test_size1 = 1.0 - TRAIN_RATIO
X = df_train["waferMap"].values
y = df_train["failureNum"].values
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y,
    test_size=test_size1,
    stratify=y,
    random_state=seed
)

#    temp를 VAL_RATIO/(VAL_RATIO+TEST_RATIO) : TEST_RATIO/(VAL_RATIO+TEST_RATIO) 로 나눠서
#    val : test = VAL_RATIO : TEST_RATIO 비율을 맞춘다.
test_size2 = TEST_RATIO / (VAL_RATIO + TEST_RATIO)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=test_size2,
    stratify=y_temp,
    random_state=seed
)

# 8) 클래스 3만 fold=1 증강 (논문의 전처리 방식과 동일)
def rot_aug(img):
    ang = random.randint(0,360)
    img_n = img / img.max()
    M = cv2.getRotationMatrix2D((18,18), ang, 1.0)
    return cv2.warpAffine(img_n, M, (36,36))

X_train_aug = list(X_train)
y_train_aug = list(y_train)
idxs3 = np.where(np.array(y_train)==3)[0]
random.shuffle(idxs3)
for ix in idxs3[:3884]:
    for a in np.unique([rot_aug(X_train[ix])], axis=0):
        X_train_aug.append(a)
        y_train_aug.append(3)

# 9) NumPy/OpenCV 전처리: (N,36,36) float32
def preprocess_images(arrays):
    out = []
    for im in arrays:
        im_n = im / im.max()
        im_r = cv2.resize(im_n, (36,36), interpolation=cv2.INTER_CUBIC)
        out.append(im_r)
    return np.stack(out).astype("float32")

wafer_tr_np  = preprocess_images(X_train_aug)
wafer_val_np = preprocess_images(X_val)
wafer_te_np  = preprocess_images(X_test)

# 10) ToTensor + Normalize → permute → 채널 추가
tf = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.2999,), (0.19235,))
])
wafer_tr_data  = tf(wafer_tr_np).permute(1,0,2)[:,None,:,:]
wafer_val_data = tf(wafer_val_np).permute(1,0,2)[:,None,:,:]
wafer_te_data  = tf(wafer_te_np).permute(1,0,2)[:,None,:,:]

train_labels = torch.tensor(y_train_aug, dtype=torch.long)
val_labels   = torch.tensor(y_val,       dtype=torch.long)
te_labels    = torch.tensor(y_test,      dtype=torch.long)

class WaferDataset(Dataset):
    def __init__(self, data, labels):
        self.data, self.labels = data, labels
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

BATCH_SIZE   = 256
train_loader = DataLoader(WaferDataset(wafer_tr_data, train_labels),
                          batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(WaferDataset(wafer_val_data, val_labels),
                          batch_size=BATCH_SIZE, shuffle=False)
test_loader  = DataLoader(WaferDataset(wafer_te_data, te_labels),
                          batch_size=BATCH_SIZE, shuffle=False)

dataloaders = (train_loader, val_loader, test_loader)
print(f"Cell 2 완료 — train: {len(train_loader)}, val: {len(val_loader)}, test: {len(test_loader)}")

# 출력 예시
print(f"Split ratios: Train {TRAIN_RATIO*100:.0f}%, Val {VAL_RATIO*100:.0f}%, Test {TEST_RATIO*100:.0f}%")

"""Wafer2Spike Model의  학습 함수 정의 및 모델 훈련"""

import torch
import torch.nn as nn
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

def test_accuracy(model, loader, criterion, device, phase="Validation"):
    model.eval()
    loss_sum, correct = 0.0, 0
    with torch.no_grad():
        for data, label in loader:
            data, label = data.to(device), label.to(device)
            out = model(data)
            loss_sum += criterion(out,label).item() * data.size(0)
            correct  += (out.argmax(1)==label).sum().item()
    avg_loss = loss_sum / len(loader.dataset)
    acc      = correct  / len(loader.dataset)
    print(f"{phase} Loss: {avg_loss:.4f}, {phase} Acc: {acc:.4f}")
    model.train()

def training(network, params,
             batch_size=256, epochs=10, lr=1e-4,
             dataloaders=None, numClasses=9,
             spike_ts=10, dropout_fc=0.3):

    train_loader, val_loader, test_loader = dataloaders
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    wafer2spike_snn = network(numClasses, dropout_fc, spike_ts, device, params=params)
    model = nn.DataParallel(wafer2spike_snn.to(device))

    criterion = nn.CrossEntropyLoss()
    decays = [
        'module.wafer2spike.conv_spk_enc_w_vdecay',
        'module.wafer2spike.conv_spk_enc_w_scdecay',
        'module.wafer2spike.Spk_conv1_w_vdecay',
        'module.wafer2spike.Spk_conv1_w_scdecay',
        'module.wafer2spike.Spk_conv2_w_vdecay',
        'module.wafer2spike.Spk_conv2_w_scdecay',
        'module.wafer2spike.Spk_fc_w_vdecay',
        'module.wafer2spike.Spk_fc_w_scdecay'
    ]
    weights_ts = ['module.wafer2spike.w_t']

    decay_params = [p for n,p in model.named_parameters() if n in decays]
    params_ts    = [p for n,p in model.named_parameters() if n in weights_ts]
    weights      = [p for n,p in model.named_parameters() if n not in decays+weights_ts]

    optimizer = torch.optim.Adam(
        [{'params':weights}, {'params':decay_params}, {'params':params_ts}],
        lr=lr
    )

    for epoch in range(1, epochs+1):
        model.train()
        loss_sum, correct = 0.0, 0
        for data, label in train_loader:
            data, label = data.to(device), label.to(device)
            optimizer.zero_grad()
            out = model(data)
            loss = criterion(out, label)
            loss.backward()
            optimizer.step()
            loss_sum += loss.item() * data.size(0)
            correct  += (out.argmax(1)==label).sum().item()

        for p in decay_params:
            p.data.clamp_(min=1e-7)

        train_loss = loss_sum / len(train_loader.dataset)
        train_acc  = correct  / len(train_loader.dataset)
        print(f"Epoch {epoch}/{epochs} — Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")

        test_accuracy(model, val_loader, criterion, device, phase="Validation")

    test_accuracy(model, test_loader, criterion, device, phase="Test")

    preds, trues = [], []
    with torch.no_grad():
        for data, label in test_loader:
            data, label = data.to(device), label.to(device)
            preds.extend(model(data).argmax(1).cpu().tolist())
            trues.extend(label.cpu().tolist())

    print("\nConfusion Matrix:")
    print(confusion_matrix(trues, preds))
    print(classification_report(trues, preds))
    return model

# 학습 실행
trained_model = training(
    network     = CurrentBasedSNN,
    params      = [0.05, 0.1, 0.08, 0.3],
    dataloaders = dataloaders
)

# DataParallel 래퍼 해제
model = trained_model.module if hasattr(trained_model, 'module') else trained_model

# ─── Cell 5: forward()만 떼서 전력 측정 ───
import time
import pynvml
import torch
from IPython.display import display

# 1) NVML 초기화 & 파워 리더 함수
pynvml.nvmlInit()
_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
def get_gpu_power():
    return pynvml.nvmlDeviceGetPowerUsage(_handle) / 1000.0  # mW → W

device = next(model.parameters()).device  # 모델이 올라간 디바이스

# 2) 한 배치만 뽑아서 미리 GPU에 올려두기
batch, _ = next(iter(test_loader))
batch = batch.to(device, non_blocking=True)

# 3) idle baseline 전력 측정 (GPU 연산 대기 상태)
idle_samples = []
for _ in range(20):         # 20번 샘플링
    idle_samples.append(get_gpu_power())
    time.sleep(0.01)        # 10ms 간격
idle_power = sum(idle_samples) / len(idle_samples)

# 4) forward 전/후 전력 샘플링
torch.cuda.synchronize()
p0 = get_gpu_power()
t0 = time.time()

# 순수 연산
_ = model(batch)

torch.cuda.synchronize()
t1 = time.time()
p1 = get_gpu_power()

# 5) 에너지 계산 (W·s → J)
energy = ((p0 + p1)/2 - idle_power) * (t1 - t0)
print(f"한 배치({batch.size(0)}개) 순수 forward 에너지: {energy:.6f} J")

# 6) 샘플당 에너지
per_sample = energy / batch.size(0)
print(f"샘플당 에너지: {per_sample*1e3:.3f} mJ")

# 7) 결과 표시
print(f"  p0={p0:.3f} W, p1={p1:.3f} W, idle={idle_power:.3f} W, Δt={t1-t0:.4f} s")

"""#본 논문에서 제안하는 구조
(GroupNorm,
역전파에서 Fast-Sigmoid 구조 사용)
"""

import torch
import torch.nn as nn
from torch.distributions.bernoulli import Bernoulli

class FastSigmoidSurrogate(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, vth, alpha=10.0):
        ctx.save_for_backward(input)
        ctx.vth = vth
        ctx.alpha = alpha
        # Heaviside-style forward
        return (input > vth).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        vth = ctx.vth
        alpha = ctx.alpha
        x = input - vth
        expm = torch.exp(-alpha * x)
        grad = alpha * expm / (1 + expm) ** 2
        return grad_output * grad, None, None


class CurrentBasedLIF(nn.Module):
    def __init__(self, conv_or_linear, bn_layer, surrogate, param):
        super(CurrentBasedLIF, self).__init__()
        self.layer     = conv_or_linear
        self.bn        = bn_layer
        self.surrogate = surrogate.apply
        # param = [w_scdecay, w_vdecay, vth, alpha]
        self.w_scdecay, self.w_vdecay, self.vth, self.alpha = param

    def forward(self, input_data, state):
        pre_spike, pre_current, pre_volt = state
        # 1) linear/conv → BatchNorm → ReLU
        x = self.layer(input_data)
        x = self.bn(x)
        x = torch.relu(x)
        # 2) LIF 업데이트
        current = self.w_scdecay * pre_current + x
        volt    = self.w_vdecay  * pre_volt  * (1. - pre_spike) + current
        # 3) surrogate spike generation
        output = self.surrogate(volt, self.vth, self.alpha)
        return output, (output, current, volt)


class CurrentBasedLIFWithDropout(nn.Module):
    def __init__(self, linear, bn_layer, surrogate, param):
        super(CurrentBasedLIFWithDropout, self).__init__()
        self.layer     = linear
        self.bn        = bn_layer
        self.surrogate = surrogate.apply
        # param = [w_scdecay, w_vdecay, vth, alpha]
        self.w_scdecay, self.w_vdecay, self.vth, self.alpha = param

    def forward(self, input_data, state, mask, train):
        pre_spike, pre_current, pre_volt = state
        x = self.layer(input_data)
        x = self.bn(x)
        x = torch.relu(x)
        if train:
            x = x * mask
        current = self.w_scdecay * pre_current + x
        volt    = self.w_vdecay  * pre_volt  * (1. - pre_spike) + current
        # pass alpha instead of cw
        output = self.surrogate(volt, self.vth, self.alpha)
        return output, (output, current, volt)


class Wafer2Spike(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(Wafer2Spike, self).__init__()
        self.device     = device
        self.spike_ts   = spike_ts
        self.dropout_fc = dropout_fc
        # params = [scdecay, vdecay, vth, alpha]
        self.scdecay, self.vdecay, self.vth, self.alpha = params

 # Conv layers + GroupNorm
        conv_enc = nn.Conv2d(1,  64, 7, stride=1, bias=True).to(device)
        gn_enc   = nn.GroupNorm(num_groups=8, num_channels=64).to(device)

        conv1    = nn.Conv2d(64, 64, 7, stride=2, bias=True).to(device)
        gn1      = nn.GroupNorm(num_groups=8, num_channels=64).to(device)

        conv2    = nn.Conv2d(64, 64, 7, stride=2, bias=True).to(device)
        gn2      = nn.GroupNorm(num_groups=8, num_channels=64).to(device)

        # FC + GroupNorm
        fc_lin   = nn.Linear(64*9, 256*9, bias=True).to(device)
        gn_fc    = nn.GroupNorm(num_groups=32, num_channels=256*9).to(device)

        # LIF modules
        self.conv_spk_enc = CurrentBasedLIF(
            conv_or_linear=conv_enc,
            bn_layer=gn_enc,           # <- 여기에 GroupNorm layer를 추가.
            surrogate=FastSigmoidSurrogate,
            param=params
        )
        self.Spk_conv1 = CurrentBasedLIF(
            conv_or_linear=conv1,
            bn_layer=gn1,              # <- 여기에 GroupNorm layer를 추가.
            surrogate=FastSigmoidSurrogate,
            param=params
        )
        self.Spk_conv2 = CurrentBasedLIF(
            conv_or_linear=conv2,
            bn_layer=gn2,              # <- 여기에 GroupNorm layer를 추가.
            surrogate=FastSigmoidSurrogate,
            param=params
        )
        self.Spk_fc = CurrentBasedLIFWithDropout(
            linear=fc_lin,
            bn_layer=gn_fc,            # <- 여기에 GroupNorm layer를 추가.
            surrogate=FastSigmoidSurrogate,
            param=params
        )

        # time-dependent weights
        self.w_t = nn.Parameter(torch.ones(self.spike_ts, device=device) / self.spike_ts)
        self.nonSpk_fc = nn.Linear(256*9, numClasses).to(device)

    def forward(self, input_data, states=None):
        batch = input_data.size(0)
        if states is None:
            states = []
            for dims in [(64,30,30), (64,12,12), (64,3,3), (256*9,)]:
                states.append(tuple(torch.zeros(batch, *dims, device=self.device) for _ in range(3)))

        mask_fc = Bernoulli(
            torch.full((batch, 256*9), 1 - self.dropout_fc, device=self.device)
        ).sample() / (1 - self.dropout_fc)

        conv_s, c1_s, c2_s, fc_s = states
        outputs = []
        for t in range(self.spike_ts):
            x, conv_s = self.conv_spk_enc(input_data, conv_s)
            x, c1_s   = self.Spk_conv1(x, c1_s)
            x, c2_s   = self.Spk_conv2(x, c2_s)
            flat      = x.view(batch, -1)
            x, fc_s   = self.Spk_fc(flat, fc_s, mask_fc, self.training)
            out       = self.nonSpk_fc(x) * self.w_t[t]
            outputs.append(out)

        return torch.stack(outputs).sum(0)


class CurrentBasedSNN(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(CurrentBasedSNN, self).__init__()
        self.wafer2spike = Wafer2Spike(numClasses, dropout_fc, spike_ts, device, params)

    def forward(self, input_data):
        # Wafer2Spike가 내부에서 상태 초기화를 처리
        return self.wafer2spike(input_data)

"""학습 함수 정의 및 모델 훈련"""

import torch
import torch.nn as nn
import numpy as np
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report

def test_accuracy(model, loader, criterion, device, phase="Validation"):
    model.eval()
    loss_sum, correct = 0.0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            loss_sum += criterion(out, y).item() * x.size(0)
            correct  += (out.argmax(1) == y).sum().item()
    avg_loss = loss_sum / len(loader.dataset)
    acc      = correct  / len(loader.dataset)
    print(f"{phase} Loss: {avg_loss:.4f}, {phase} Acc: {acc:.4f}")
    model.train()
    return acc

def training(network,
             params,
             dataloaders,
             spike_ts     = 10,
             batch_size   = 256,
             epochs       = 20,
             lr           = 1e-4,
             dropout_fc   = 0.20,
             weight_decay = 1e-5,
             alpha_wd     = 0.0,
             patience_lr  = 2,
             patience_es  = 3):

    train_loader, val_loader, test_loader = dataloaders
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 1) 모델 인스턴스화
    model = network(
    9,               # num_classes
    dropout_fc,      # dropout_fc
    spike_ts,        # spike_ts
    device,          # device
    params           # params
    )
    model = nn.DataParallel(model.to(device))

    # 2) 클래스 가중치
    all_labels = torch.cat([y for _, y in train_loader], dim=0).cpu().numpy()
    counts = np.bincount(all_labels, minlength=9)
    wts = 1.0 / counts
    wts = wts / wts.sum() * 9
    weight_tensor = torch.tensor(wts, dtype=torch.float32, device=device)
    criterion = nn.CrossEntropyLoss(weight=weight_tensor)

    # 3) Optimizer
    thr_params   = [p for n,p in model.named_parameters() if 'w_t' in n]
    other_params = [p for n,p in model.named_parameters() if 'w_t' not in n]
    optimizer = torch.optim.Adam([
        {'params': other_params, 'weight_decay': weight_decay},
        {'params': thr_params,   'weight_decay': alpha_wd}
    ], lr=lr)

    # 4) Scheduler & EarlyStopping
    scheduler = ReduceLROnPlateau(optimizer, mode='max',
                                  factor=0.5, patience=patience_lr,
                                  verbose=True)
    best_val_acc, es_count = 0.0, 0

    # 5) 학습 루프
    for epoch in range(1, epochs+1):
        model.train()
        tr_loss, tr_corr = 0.0, 0
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            out  = model(x)
            loss = criterion(out, y)
            loss.backward()
            optimizer.step()
            tr_loss += loss.item() * x.size(0)
            tr_corr += (out.argmax(1) == y).sum().item()

        tr_loss /= len(train_loader.dataset)
        tr_acc   = tr_corr / len(train_loader.dataset)
        print(f"Epoch {epoch}/{epochs} — Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}")

        val_acc = test_accuracy(model, val_loader, criterion, device, phase="Validation")
        scheduler.step(val_acc)
        if val_acc > best_val_acc:
            best_val_acc, es_count = val_acc, 0
        else:
            es_count += 1
            if es_count >= patience_es:
                print(f"Early stopping at epoch {epoch}, best val_acc={best_val_acc:.4f}")
                break

    # 6) 최종 Test 평가
    test_acc = test_accuracy(model, test_loader, criterion, device, phase="Test")

    # 7) Confusion Matrix & Report
    all_preds, all_trues = [], []
    model.eval()
    with torch.no_grad():
        for x, y in test_loader:
            x, y = x.to(device), y.to(device)
            preds = model(x).argmax(1)
            all_preds.extend(preds.cpu().tolist())
            all_trues.extend(y.cpu().tolist())

    print("\nConfusion Matrix:")
    print(confusion_matrix(all_trues, all_preds))
    print("\nClassification Report:")
    print(classification_report(all_trues, all_preds, digits=4))

    return model

#  학습 실행 예시
trained_model = training(
    network      = CurrentBasedSNN,
    params       = [0.05, 0.10, 0.08, 5.0],  # [scDecay, vDecay, vTh, alpha]
    dataloaders  = dataloaders,
    spike_ts     = 10,
    batch_size   = 256,
    epochs       = 20,
    lr           = 1e-4,
    dropout_fc   = 0.20,
    weight_decay = 1e-5,
    alpha_wd     = 0.0,
    patience_lr  = 2,
    patience_es  = 3
)

#최적의 하이퍼파라미터 탐색.
"""
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score

def run_experiment(group_count, lr, dropout_rate, epochs=10, device='cuda'):
    # 모델 정의
    model = CurrentBasedSNN(9, dropout_rate, spike_ts=10, device=device,
                            params=[0.05, 0.10, 0.08, 5.0])
    # GroupNorm 그룹 수 조정
    for module in model.wafer2spike.modules():
        if isinstance(module, nn.GroupNorm):
            module.num_groups = group_count

    model = nn.DataParallel(model).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    # 학습
    for epoch in range(epochs):
        model.train()
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            out = model(xb)
            loss = criterion(out, yb)
            loss.backward()
            optimizer.step()

    # 검증 정확도 계산
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for xb, yb in val_loader:
            xb = xb.to(device)
            out = model(xb).argmax(1).cpu().numpy()
            preds.extend(out)
            trues.extend(yb.numpy())
    acc = accuracy_score(trues, preds)
    return acc

# 하이퍼파라미터 그리드
group_counts = [8, 16]
learning_rates = [1e-4, 1e-3]
dropout_rates = [0.3, 0.2]

results = []
for g in group_counts:
    for lr in learning_rates:
        for d in dropout_rates:
            acc = run_experiment(g, lr, d)
            results.append({'groups': g, 'lr': lr, 'dropout': d, 'val_acc': acc})
            print(f"groups={g}, lr={lr}, dropout={d} -> acc={acc:.4f}")

df_results = pd.DataFrame(results)
print(df_results)
"""

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=10, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 9 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=9, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 8 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=8, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 7 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=7, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print(" Test Classification Report:")
print(classification_report(trues, preds, digits=4))

final_trained_model=model

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt

# ─── 1) 테스트 평가 ───
final_trained_model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = final_trained_model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

# ─── 2) Classification Report ───
print(" Test Classification Report:")
print(classification_report(trues, preds, digits=4))

# ─── 3) Confusion Matrix (raw counts) ───
cm = confusion_matrix(trues, preds)
print(" Confusion Matrix:")
print(cm)

# ─── 4) Confusion Matrix (normalized & plot) ───
# 클래스 이름 (필요에 따라 수정)
labels = ['Center','Donut','Edge-Loc','Edge-Ring','Loc',
          'Random','Scratch','Near-full','No-Pattern']

# 행별 정규화
cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)
fig, ax = plt.subplots(figsize=(7,7))

# 1) 연한 블루 계열 컬러맵 사용
im = ax.imshow(cm_norm, aspect='equal', cmap='Blues', vmin=0, vmax=1)

# 2) 컬러바
cbar = fig.colorbar(im, ax=ax)
cbar.set_label('Normalized frequency')

# 3) 축 레이블
ax.set_xticks(np.arange(len(labels)))
ax.set_yticks(np.arange(len(labels)))
ax.set_xticklabels(labels, rotation=45, ha='right')
ax.set_yticklabels(labels)
ax.set_xlabel('Predicted label')
ax.set_ylabel('True label')
ax.set_title('Testing Normalized Confusion Matrix')

# 4) 텍스트 컬러 임계값 낮춰 가독성 개선
#    값이 0.3 이상이면 흰색, 아니면 검은색
thresh = 0.3
for i in range(cm_norm.shape[0]):
    for j in range(cm_norm.shape[1]):
        val = cm_norm[i, j]
        color = 'white' if val > thresh else 'black'
        ax.text(j, i, f'{val:.2f}',
                ha='center', va='center',
                color=color, fontsize=9, fontweight='bold')

plt.tight_layout()
plt.show()

"""#각 층의 출력 시각화"""

import torch
import matplotlib.pyplot as plt

# 1) 저장해둔 최적 모델 불러오기
# (이미 final_trained_model에 학습된 상태가 들어 있다고 가정)
net = final_trained_model
net.eval()

# 2) 활성화 저장용 딕셔너리
spk1_activation = {}

# 3) 훅 함수 정의
def hook_fn(module, inp, out):
    # out은 (spike, (spike, current, volt)) 튜플
    spike, _ = out
    # CPU로 복사해 두기
    spk1_activation['spk1'] = spike.detach().cpu()

# 4) 원하는 레이어에 훅 등록
hook = net.module.wafer2spike.conv_spk_enc.register_forward_hook(hook_fn)

# 5) 테스트 데이터 한 배치 흘려 보내기 (weight update 없음)
with torch.no_grad():
    xb, _ = next(iter(test_loader))
    _ = net(xb.to(device))

# 6) 훅 제거 — 꼭 해 줘야 다음 호출에 중복 등록되지 않습니다
hook.remove()

# 7) 꺼내서 시각화
spk1 = spk1_activation['spk1']    # shape: [B, C, H, W]
plt.figure(figsize=(4,4))
plt.imshow(spk1[0, 0], cmap='gray', aspect='equal')
plt.title("conv_spk_enc Spike Map (sample 0, channel 0)")
plt.axis('off')
plt.show()

import torch
import matplotlib.pyplot as plt
import numpy as np

# 1) 최적 모델 준비
net = final_trained_model
net.eval()

# 2) 훅으로 스파이크 캡처
spk_dict = {}
def hook_fn(module, inp, out):
    spike, _ = out
    spk_dict['spk'] = spike.detach().cpu()
hook = net.module.wafer2spike.Spk_conv1.register_forward_hook(hook_fn)

with torch.no_grad():
    xb, _ = next(iter(test_loader))
    _ = net(xb.to(device))
hook.remove()

# 3) 데이터 준비
spk = spk_dict['spk']    # [B, C, H, W]
batch0 = spk[0]          # 첫 배치

B, C, H, W = spk.shape
full_size = H * W

# 4) 채널별 스파이크 수
counts = batch0.sum(dim=(1,2)).numpy()  # shape [C]

# 5) “부분 스파이크” 채널만 필터링
valid = np.where((counts > 0) & (counts < full_size))[0]
if len(valid)==0:
    raise RuntimeError("부분 스파이크 채널이 없습니다.")
best_ch = valid[np.argmax(counts[valid])]

print(f"Best non-saturated channel: {best_ch}, spikes={counts[best_ch]} / {full_size}")

# 6) 시각화
plt.figure(figsize=(4,4))
plt.imshow(batch0[best_ch].numpy(),
           cmap='gray_r',  # 반전 그레이: 1→흰, 0→검
           vmin=0, vmax=1,
           interpolation='nearest')
plt.title(f"Spk_conv1 Spike Map (batch=0, channel={best_ch})")
plt.axis('off')
plt.show()

"""#사용한 logistic sigmoid 함수 출력"""

import numpy as np
import matplotlib.pyplot as plt

# Fast-Sigmoid surrogate gradient parameters
alpha = 5.0
vth = 0.0

# Input range for plotting
x = np.linspace(-1.0, 1.0, 400)

# Compute gradient: α·e^(−α(x−vth)) / (1 + e^(−α(x−vth)))²
expm = np.exp(-alpha * (x - vth))
grad = alpha * expm / (1 + expm) ** 2

# Plot
plt.figure()
plt.plot(x, grad)
plt.title("Logistic Surrogate Gradient")
plt.xlabel("Input - Threshold")
plt.ylabel("Gradient")
plt.grid(True)
plt.show()

# DataParallel 래퍼 해제
model = trained_model.module if hasattr(trained_model, 'module') else trained_model

# ─── Cell 5: forward()만 떼서 전력 측정 ───
import time
import pynvml
import torch
from IPython.display import display

# 1) NVML 초기화 & 파워 리더 함수
pynvml.nvmlInit()
_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
def get_gpu_power():
    return pynvml.nvmlDeviceGetPowerUsage(_handle) / 1000.0  # mW → W

device = next(model.parameters()).device  # 모델이 올라간 디바이스

# 2) 한 배치만 뽑아서 미리 GPU에 올려두기
batch, _ = next(iter(test_loader))
batch = batch.to(device, non_blocking=True)

# 3) idle baseline 전력 측정 (GPU 연산 대기 상태)
idle_samples = []
for _ in range(20):         # 20번 샘플링
    idle_samples.append(get_gpu_power())
    time.sleep(0.01)        # 10ms 간격
idle_power = sum(idle_samples) / len(idle_samples)

# 4) forward 전/후 전력 샘플링
torch.cuda.synchronize()
p0 = get_gpu_power()
t0 = time.time()

# 순수 연산
_ = model(batch)

torch.cuda.synchronize()
t1 = time.time()
p1 = get_gpu_power()

# 5) 에너지 계산 (W·s → J)
energy = ((p0 + p1)/2 - idle_power) * (t1 - t0)
print(f"한 배치({batch.size(0)}개) 순수 forward 에너지: {energy:.6f} J")

# 6) 샘플당 에너지
per_sample = energy / batch.size(0)
print(f"샘플당 에너지: {per_sample*1e3:.3f} mJ")

# 7) 결과 표시
print(f"  p0={p0:.3f} W, p1={p1:.3f} W, idle={idle_power:.3f} W, Δt={t1-t0:.4f} s")

# Commented out IPython magic to ensure Python compatibility.
# #Idle 전력 측정 (idle_duration 동안 주기적으로 전력 측정 후 평균)
# #순수 추론 전력 계산: 측정된 전력에서 idle 평균을 빼고 적분
# %%bash
# cat << 'EOF' > gpu_power_measurement.py
# import time
# import torch
# import pynvml
# import pandas as pd
# from torch.utils.data import DataLoader
# from typing import Tuple
# 
# pynvml.nvmlInit()
# _handle = pynvml.nvmlDeviceGetHandleByIndex(0)
# 
# def get_gpu_power() -> float:
#     return pynvml.nvmlDeviceGetPowerUsage(_handle) / 1000.0
# 
# def measure_inference_power(
#     model: torch.nn.Module,
#     dataloader: DataLoader,
#     device: str = 'cuda',
#     idle_duration: float = 1.0,
#     sample_interval: float = 0.05
# ) -> Tuple[float, pd.DataFrame]:
#     # 1) Idle 전력 측정
#     idle_samples = []
#     t0 = time.time()
#     while time.time() - t0 < idle_duration:
#         idle_samples.append(get_gpu_power())
#         time.sleep(sample_interval)
#     idle_power = sum(idle_samples) / len(idle_samples)
# 
#     # 2) 추론 중 전력 측정
#     model.eval().to(device)
#     timestamps, raw_powers = [], []
#     t_start = time.time()
#     t_next = t_start
# 
#     with torch.no_grad():
#         for xb, _ in dataloader:
#             xb = xb.to(device)
#             now = time.time()
#             if now >= t_next:
#                 timestamps.append(now - t_start)
#                 raw_powers.append(get_gpu_power())
#                 t_next += sample_interval
#             _ = model(xb)
# 
#     t_end = time.time()
#     timestamps.append(t_end - t_start)
#     raw_powers.append(get_gpu_power())
# 
#     # 3) Idle 보정 및 에너지 적분
#     corrected = [p - idle_power for p in raw_powers]
#     energy = 0.0
#     for i in range(len(corrected)-1):
#         dt = timestamps[i+1] - timestamps[i]
#         energy += max((corrected[i] + corrected[i+1]) / 2, 0.0) * dt
# 
#     log_df = pd.DataFrame({
#         'time_s': timestamps,
#         'raw_power_W': raw_powers,
#         'idle_power_W': idle_power,
#         'corrected_power_W': corrected
#     })
# 
#     return energy, log_df
# EOF

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 1) 모델, 옵티마이저, 손실함수 (첫 번째 셀과 동일)
model = CurrentBasedSNN(9, best_dropout, spike_ts=7, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
for m in model.wafer2spike.modules():
    if isinstance(m, nn.GroupNorm):
        m.num_groups = best_groups
model = nn.DataParallel(model).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 2) 지표 기록용 리스트 초기화
num_epochs = 10
train_losses, val_losses = [], []
train_accs,   val_accs   = [], []

# 3) 에포크별 학습·검증 루프
for epoch in range(1, num_epochs+1):
    # --- Train ---
    model.train()
    running_loss = running_correct = running_total = 0
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

        running_loss    += loss.item() * xb.size(0)
        running_correct += (out.argmax(1)==yb).sum().item()
        running_total   += xb.size(0)
    tr_loss = running_loss / running_total
    tr_acc  = running_correct / running_total

    # --- Validate ---
    model.eval()
    v_loss = v_corr = v_tot = 0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            out = model(xb)
            l = criterion(out, yb)
            v_loss += l.item() * xb.size(0)
            v_corr += (out.argmax(1)==yb).sum().item()
            v_tot  += xb.size(0)
    vl_loss = v_loss / v_tot
    vl_acc  = v_corr / v_tot

    # --- 기록 & 로그 ---
    train_losses.append(tr_loss)
    train_accs.append(tr_acc)
    val_losses.append(vl_loss)
    val_accs.append(vl_acc)
    print(f"[{epoch}/{num_epochs}]  Train: loss={tr_loss:.4f}, acc={tr_acc:.4f}  |  Val: loss={vl_loss:.4f}, acc={vl_acc:.4f}")

# 5) Loss & Accuracy 그래프 (한 Figure에 두 개)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))

ax1.plot(range(1, num_epochs+1), train_losses, '-o', label='Train Loss')
ax1.plot(range(1, num_epochs+1), val_losses,   '-o', label='Val Loss')
ax1.set_title('Loss Curve'); ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss')
ax1.legend(); ax1.grid(True)

ax2.plot(range(1, num_epochs+1), train_accs, '-o', label='Train Acc')
ax2.plot(range(1, num_epochs+1), val_accs,   '-o', label='Val Acc')
ax2.set_title('Accuracy Curve'); ax2.set_xlabel('Epoch'); ax2.set_ylabel('Accuracy')
ax2.legend(); ax2.grid(True)

plt.tight_layout()
plt.show()
